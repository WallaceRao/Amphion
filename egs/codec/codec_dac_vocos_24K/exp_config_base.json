{
    // "base_config": "config/tts.json",
    "model_type": "Codec",
    "dataset": ["libritts-train-clean-100"],
    "preprocess": {
        "hop_size": 480,
        "sample_rate": 24000,
        "max_length": 36000,
        "processed_dir": "/home/t-zeqianju/yuancwang/temp_test_dataset",
        "valid_file": "valid.json",
        "train_file": "train.json"
    },
    "model": {
        "encoder": {
            "d_model": 96,
            "up_ratios": [3, 4, 5, 8],
            "out_channels": 256,
            "use_tanh": false
        },
        "decoder": {
            "in_channel": 256,
            "upsample_initial_channel": 1536,
            "up_ratios": [8, 5, 4, 3],
            "num_quantizers": 12,
            "codebook_size": 1024,
            "codebook_dim": 8,
            "quantizer_type": "fvq",
            "quantizer_dropout": 0.5,
            "commitment": 0.25,
            "codebook_loss_weight": 1.0,
            "use_l2_normlize": true,
            "codebook_type": "euclidean",
            "kmeans_init": false,
            "kmeans_iters": 10,
            "decay": 0.8,
            "eps": 0.5,
            "threshold_ema_dead_code": 2,
            "weight_init": false,
            "use_vocos": true,
            "vocos_dim": 512,
            "vocos_intermediate_dim": 4096,
            "vocos_num_layers": 30,
            "n_fft": 1920,
            "hop_size": 480,
            "padding": "same"
        },
        "period_gan": {
            "max_downsample_channels": 512,
            "channels": 32,
            "channel_increasing_factor": 2
        },
        "spec_gan": {
            "stft_params": {
                "fft_sizes": [128, 256, 512, 1024, 2048],
                "hop_sizes": [32, 64, 128, 256, 512],
                "win_lengths": [128, 256, 512, 1024, 2048],
                "window": "hann_window"
            },
            "in_channels": 1,
            "out_channels": 1,
            "channels": 32,
            "kernel_size": [5, 3],
            "max_downsample_channels": 512,
            "down_scales": [2, 2, 2],
            "use_weight_norm": true,
            "use_complex": false
        }
    },
    "loss": {
        "mel_loss": {
            "sample_rate": 24000
        },
        "disc_loss_weight": 1.0,
        "mel_loss_weight": 10.0,
        "adv_loss_weight": 2.0,
        "fm_loss_weight": 2.0,
        "spec_fm_loss_weight": 1.0,
        "vq_loss_weight": 1.0
    },
    "log_dir": "/blob/v-yuancwang/codec_ckpt/codec_amphion",
    "train": {
        "max_epoch": 0,
        "use_dynamic_batchsize": false,
        "max_tokens": 16000000,
        "max_sentences": 200,
        "lr_warmup_steps": 10000,
        "lr_scheduler": {
            "warmup_step": 10000,
            "min_lr": 1e-4,
            "max_lr": 2e-4
        },
        "num_train_steps": 100000,
        "adam_g": {
            "lr": 2e-4,
            "betas": [0.5, 0.9]
        },
        "adam_d": {
            "lr": 2e-4,
            "betas": [0.5, 0.9]
        },
        "ddp": false,
        "random_seed": 114,
        "batch_size": 24,   // use batch_size if not use dynamic batchsize
        "epochs": 5000,
        "max_steps": 1000000,
        "total_training_steps": 800000,
        "save_summary_steps": 500,
        "save_checkpoints_steps": 1000,
        "valid_interval": 2000,
        "keep_checkpoint_max": 100,
        "gradient_accumulation_step": 1,
        "tracker": ["tensorboard"],
        "save_checkpoint_stride": [1],
        "keep_last": [1],
        "run_eval": [true],
        "dataloader": {
          "num_worker": 4,
          "pin_memory": true
        }
    }
    // "trans_exp": {
    //     "dataset_list":["mls_train"],
    //     "cache_dir": "/mnt/petrelfs/hehaorui/data/exp_cache/vc/",
    //     "use_speaker": false,
    //     "use_noise": false,
    //     "noise_dir": "/mnt/petrelfs/hehaorui/data/noise/audiocaps",
    //     "content_model_path": "/mnt/petrelfs/hehaorui/data/pretrained_ckpts/mhubert"
    // }
}